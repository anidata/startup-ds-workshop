{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to ETL with Luigi\n",
    "In this module we will cover the basic principles of how to craft a data pipeline.\n",
    "\n",
    "This consists of three distinct stages:\n",
    "- Extract (fetch data from a remote source)\n",
    "- Transform (clean, aggregate, and modify the data)\n",
    "- Load (insert the transformed data into a database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What is Luigi?\n",
    "Luigi is a python framework for creating data pipelines, and provides two concepts we will use to represent what we need to accomplish.\n",
    "- Task: unit of work being done\n",
    "- Target: the things we're doing work on\n",
    "\n",
    "In this case, we will make a task for each of the E T and L, and pass targets inbetween each task.  The targets will represent files at various stages of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What goes into a Task?\n",
    "Each task requires three things:\n",
    "- The work being done (run method)\n",
    "- Whether the task has completed or not (all the output targets exist)\n",
    "- Any other tasks that need to run to completion before starting the task at hand (requires method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anything else?\n",
    "If a task needs to be configured, we can add Parameters to add changeable details.\n",
    "\n",
    "Also, we'll be using a data manipulation library called `pandas` to transform the data.  If you're used to using Excel, you can think of it as the python code replacement (and much more!).  \n",
    "\n",
    "Pandas offers us two concepts to work with:\n",
    "- DataFrame: a multi dimentional data representation (spreadsheet with many columns)\n",
    "- Series: a one dimentional data representation (single column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what does a Task look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example adapted from http://help.mortardata.com/technologies/luigi/how_luigi_works\n",
    "import luigi\n",
    "\n",
    "class TransformTask(luigi.Task):\n",
    "\n",
    "    # Example parameter for our task: a \n",
    "    # name to save out output file\n",
    "    output_filename = luigi.Parameter(default='output.csv')\n",
    "\n",
    "    def requires(self):\n",
    "        \"\"\"\n",
    "        Which other Tasks need to be complete before\n",
    "        this Task can start? Luigi will use this to \n",
    "        compute the task dependency graph.\n",
    "        \"\"\"\n",
    "        return ExtractTask()\n",
    "\n",
    "    def output(self):\n",
    "        \"\"\"\n",
    "        When this Task is complete, where will it produce output?\n",
    "        Luigi will check whether this output (specified as a Target) \n",
    "        exists to determine whether the Task needs to run at all.\n",
    "        \"\"\"\n",
    "        return luigi.LocalTarget(self.output_filename)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        How do I run this Task?\n",
    "        Luigi will call this method if the Task needs to be run.\n",
    "        \"\"\"\n",
    "        # We can do anything we want in here, from calling python\n",
    "        # methods to running shell scripts to calling APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we use the targets when we run the task?\n",
    "An example of the run method in a transform task uses both input and output targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(self):\n",
    "    # grab target from input\n",
    "    input_target = self.input() # a.k.a self.requires().output()\n",
    "    # grab the output target as well\n",
    "    output_target = self.output()\n",
    "    # open both target files\n",
    "    with input_target.open('r') as it, output_target.open('w') as ot:\n",
    "        # read file and convert to dataframe\n",
    "        dataframe = pandas.read_csv(it)\n",
    "        # do some stuff to the data\n",
    "        dataframe['koolaid'] = pd.Series(['oh', 'yeeeeaaahh'])\n",
    "        # output data as csv\n",
    "        dataframe.to_csv(ot, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we execute all of the tasks\n",
    "Since all of the tasks are grouped in a chain, each requiring the previous to run before it can, we only need to call execution on the last task (LoadTask).  We do this by adding a main function to our script, which will look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    luigi.run(['LoadTask', '--local-scheduler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luigi will check LoadTask, see that it requires TransformTask to run before it, then see that TransformTask requires ExtractTask.  ExtractTask doesn't have any requirements, which means that while we specify LoadTask to execute, ExtractTask will run First.  \n",
    "\n",
    "Finally, run your script as usual `python etl.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra information to help you along\n",
    "- use the `requests` package to fetch files from the web with the `get` method\n",
    "- use the `pandas` package to aggregate the data\n",
    "- also use `pandas` to load the data into the database with the `to_sql` method\n",
    "- use the `sqlite3` package to act as a local database (doesn't require login credentials to get a connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals for your pipeline\n",
    "- Extract the titanic dataset from the url https://goo.gl/xMsy16\n",
    "- Aggregate the number of passengers per class\n",
    "  - groupby Pclass column, select Pclass column, then count()\n",
    "- Load aggregate data into a database (sqlite3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anidata-workshop)",
   "language": "python",
   "name": "conda_anidata-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
